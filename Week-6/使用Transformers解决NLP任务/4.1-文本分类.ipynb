{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "Êú¨ÊñáÊ∂âÂèäÁöÑjupter notebookÂú®[ÁØáÁ´†4‰ª£Á†ÅÂ∫ì‰∏≠](https://github.com/datawhalechina/learn-nlp-with-transformers/tree/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1)„ÄÇ\n",
    "\n",
    "‰πüÁõ¥Êé•‰ΩøÁî®google colab notebookÊâìÂºÄÊú¨ÊïôÁ®ãÔºå‰∏ãËΩΩÁõ∏ÂÖ≥Êï∞ÊçÆÈõÜÂíåÊ®°Âûã„ÄÇ\n",
    "Â¶ÇÊûúÊÇ®Ê≠£Âú®googleÁöÑcolab‰∏≠ÊâìÂºÄËøô‰∏™notebookÔºåÊÇ®ÂèØËÉΩÈúÄË¶ÅÂÆâË£ÖTransformersÂíåü§óDatasetsÂ∫ì„ÄÇÂ∞Ü‰ª•‰∏ãÂëΩ‰ª§ÂèñÊ∂àÊ≥®ÈáäÂç≥ÂèØÂÆâË£Ö„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MOsHUjgdIrIW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.24.0\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl.metadata (90 kB)\n",
      "     ---------------------------------------- 0.0/90.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/90.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/90.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/90.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/90.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/90.5 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/90.5 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/90.5 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 41.0/90.5 kB 326.8 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 61.4/90.5 kB 465.5 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 61.4/90.5 kB 465.5 kB/s eta 0:00:01\n",
      "     ---------------------------------- --- 81.9/90.5 kB 305.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 90.5/90.5 kB 321.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from transformers==4.24.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from transformers==4.24.0) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from transformers==4.24.0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from transformers==4.24.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from transformers==4.24.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from transformers==4.24.0) (2024.5.15)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from transformers==4.24.0) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.24.0)\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from transformers==4.24.0) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.9.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from tqdm>=4.27->transformers==4.24.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from requests->transformers==4.24.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from requests->transformers==4.24.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from requests->transformers==4.24.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\data_analysis\\lib\\site-packages (from requests->transformers==4.24.0) (2024.2.2)\n",
      "Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.5 MB 1.4 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.0/5.5 MB 495.5 kB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.0/5.5 MB 495.5 kB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.0/5.5 MB 495.5 kB/s eta 0:00:11\n",
      "    --------------------------------------- 0.1/5.5 MB 383.3 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.1/5.5 MB 350.1 kB/s eta 0:00:16\n",
      "    --------------------------------------- 0.1/5.5 MB 350.1 kB/s eta 0:00:16\n",
      "    --------------------------------------- 0.1/5.5 MB 328.4 kB/s eta 0:00:17\n",
      "    --------------------------------------- 0.1/5.5 MB 328.4 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.1/5.5 MB 341.3 kB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.2/5.5 MB 316.5 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.2/5.5 MB 316.5 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.2/5.5 MB 316.5 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.2/5.5 MB 316.5 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.2/5.5 MB 316.5 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.2/5.5 MB 228.2 kB/s eta 0:00:24\n",
      "   - -------------------------------------- 0.2/5.5 MB 228.2 kB/s eta 0:00:24\n",
      "   - -------------------------------------- 0.2/5.5 MB 244.1 kB/s eta 0:00:22\n",
      "   - -------------------------------------- 0.2/5.5 MB 244.1 kB/s eta 0:00:22\n",
      "   - -------------------------------------- 0.2/5.5 MB 244.1 kB/s eta 0:00:22\n",
      "   - -------------------------------------- 0.2/5.5 MB 240.4 kB/s eta 0:00:22\n",
      "   -- ------------------------------------- 0.3/5.5 MB 327.7 kB/s eta 0:00:16\n",
      "   -- ------------------------------------- 0.4/5.5 MB 361.9 kB/s eta 0:00:15\n",
      "   -- ------------------------------------- 0.4/5.5 MB 361.0 kB/s eta 0:00:15\n",
      "   --- ------------------------------------ 0.4/5.5 MB 364.1 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 0.5/5.5 MB 375.7 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 0.5/5.5 MB 388.2 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 0.5/5.5 MB 388.2 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 0.5/5.5 MB 388.2 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 0.5/5.5 MB 388.2 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 0.5/5.5 MB 353.6 kB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 373.5 kB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 373.5 kB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 390.5 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 394.6 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 420.0 kB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 420.0 kB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 417.2 kB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 0.8/5.5 MB 429.3 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 0.8/5.5 MB 435.1 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 0.8/5.5 MB 436.9 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 0.8/5.5 MB 436.9 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 0.9/5.5 MB 445.7 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 1.0/5.5 MB 498.0 kB/s eta 0:00:09\n",
      "   ------- -------------------------------- 1.1/5.5 MB 507.6 kB/s eta 0:00:09\n",
      "   ------- -------------------------------- 1.1/5.5 MB 514.7 kB/s eta 0:00:09\n",
      "   -------- ------------------------------- 1.1/5.5 MB 517.7 kB/s eta 0:00:09\n",
      "   -------- ------------------------------- 1.2/5.5 MB 529.9 kB/s eta 0:00:09\n",
      "   -------- ------------------------------- 1.2/5.5 MB 527.1 kB/s eta 0:00:09\n",
      "   -------- ------------------------------- 1.2/5.5 MB 527.1 kB/s eta 0:00:09\n",
      "   -------- ------------------------------- 1.2/5.5 MB 527.1 kB/s eta 0:00:09\n",
      "   -------- ------------------------------- 1.2/5.5 MB 527.1 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.3/5.5 MB 512.6 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.3/5.5 MB 524.3 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 1.3/5.5 MB 524.3 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 1.4/5.5 MB 527.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 522.7 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 527.5 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 527.5 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 527.5 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 527.5 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.5/5.5 MB 522.9 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 1.7/5.5 MB 567.7 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 1.8/5.5 MB 603.4 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 1.8/5.5 MB 607.9 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 1.9/5.5 MB 615.3 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 1.9/5.5 MB 615.9 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.0/5.5 MB 622.6 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.0/5.5 MB 626.3 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.0/5.5 MB 626.3 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.0/5.5 MB 626.3 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.0/5.5 MB 626.3 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 2.1/5.5 MB 622.0 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 2.1/5.5 MB 622.0 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 2.1/5.5 MB 622.0 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 2.2/5.5 MB 608.9 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 2.2/5.5 MB 609.1 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 615.6 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 610.5 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 610.5 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 610.5 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 2.3/5.5 MB 609.8 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 2.3/5.5 MB 609.8 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 2.3/5.5 MB 609.8 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 608.3 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 611.6 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 2.5/5.5 MB 619.9 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 2.7/5.5 MB 648.0 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 2.8/5.5 MB 677.7 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 2.9/5.5 MB 682.3 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.9/5.5 MB 684.6 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.9/5.5 MB 684.4 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 3.0/5.5 MB 686.3 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 3.0/5.5 MB 686.3 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 3.0/5.5 MB 686.3 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 3.0/5.5 MB 664.6 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 3.0/5.5 MB 666.7 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 3.0/5.5 MB 671.3 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 673.3 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 673.3 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 673.3 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 673.3 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 3.3/5.5 MB 676.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 3.3/5.5 MB 680.8 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 3.3/5.5 MB 682.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 3.4/5.5 MB 688.6 kB/s eta 0:00:04\n",
      "   ------------------------- -------------- 3.4/5.5 MB 690.5 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.5/5.5 MB 698.4 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.5/5.5 MB 698.4 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.6/5.5 MB 697.7 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 3.6/5.5 MB 693.1 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 3.8/5.5 MB 726.1 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 731.3 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 736.5 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 4.0/5.5 MB 737.6 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 4.0/5.5 MB 740.9 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 743.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 746.9 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.1/5.5 MB 748.3 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.2/5.5 MB 751.2 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.2/5.5 MB 751.2 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.2/5.5 MB 751.2 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.2/5.5 MB 751.2 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.2/5.5 MB 731.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.3/5.5 MB 736.5 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.3/5.5 MB 736.2 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.3/5.5 MB 736.2 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.3/5.5 MB 736.2 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.3/5.5 MB 716.7 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.4/5.5 MB 723.3 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 4.4/5.5 MB 721.0 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 4.5/5.5 MB 728.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 4.7/5.5 MB 749.5 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 754.0 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 775.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.9/5.5 MB 778.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 780.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 781.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.1/5.5 MB 780.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.5 MB 789.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.5 MB 790.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 792.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 792.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 792.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 792.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 775.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 778.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 778.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 778.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 778.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 767.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 764.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 767.3 kB/s eta 0:00:00\n",
      "Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/3.5 MB 1.7 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.1/3.5 MB 1.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.2/3.5 MB 1.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.2/3.5 MB 1.2 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.2/3.5 MB 1.2 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.2/3.5 MB 1.2 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.2/3.5 MB 1.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.3/3.5 MB 713.1 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.3/3.5 MB 778.3 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.3/3.5 MB 746.0 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.3/3.5 MB 746.0 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.3/3.5 MB 746.0 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.3/3.5 MB 746.0 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.5/3.5 MB 786.4 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.5/3.5 MB 786.4 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.5/3.5 MB 786.4 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.6/3.5 MB 749.6 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.6/3.5 MB 753.1 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.8/3.5 MB 839.9 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.0/3.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.2/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.2/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.3/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.5/3.5 MB 983.5 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.5/3.5 MB 983.2 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.5/3.5 MB 983.2 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.7/3.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.7/3.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.7/3.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.0/3.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.2/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.3/3.5 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.3/3.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.3/3.5 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.4/3.5 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.4/3.5 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.4/3.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.4/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.5/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.6/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.6/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.6/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.6/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.6/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.6/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.7/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.8/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.8/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.0/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.1/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.2/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.2/3.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.3/3.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.3/3.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.41.1\n",
      "    Uninstalling transformers-4.41.1:\n",
      "      Successfully uninstalled transformers-4.41.1\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Anaconda\\envs\\data_analysis\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers datasets\n",
    "!pip install transformers==4.24.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFASsisvIrIb"
   },
   "source": [
    "Â¶ÇÊûúÊÇ®Ê≠£Âú®Êú¨Âú∞ÊâìÂºÄËøô‰∏™notebookÔºåËØ∑Á°Æ‰øùÊÇ®Â∑≤ÁªèËøõË°å‰∏äËø∞‰æùËµñÂåÖÁöÑÂÆâË£Ö„ÄÇ\n",
    "ÊÇ®‰πüÂèØ‰ª•Âú®[ËøôÈáå](https://github.com/huggingface/transformers/tree/master/examples/text-classification)ÊâæÂà∞Êú¨notebookÁöÑÂ§öGPUÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÁâàÊú¨„ÄÇ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÊñáÊú¨ÂàÜÁ±ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTCFado4IrIc"
   },
   "source": [
    "Êàë‰ª¨Â∞ÜÂ±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî® [ü§ó Transformers](https://github.com/huggingface/transformers)‰ª£Á†ÅÂ∫ì‰∏≠ÁöÑÊ®°ÂûãÊù•Ëß£ÂÜ≥ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°Ôºå‰ªªÂä°Êù•Ê∫ê‰∫é[GLUE Benchmark](https://gluebenchmark.com/).\n",
    "\n",
    "![Widget inference on a text classification task](https://github.com/huggingface/notebooks/blob/master/examples/images/text_classification.png?raw=1)\n",
    "\n",
    "GLUEÊ¶úÂçïÂåÖÂê´‰∫Ü9‰∏™Âè•Â≠êÁ∫ßÂà´ÁöÑÂàÜÁ±ª‰ªªÂä°ÔºåÂàÜÂà´ÊòØÔºö\n",
    "- [CoLA](https://nyu-mll.github.io/CoLA/) (Corpus of Linguistic Acceptability) Èâ¥Âà´‰∏Ä‰∏™Âè•Â≠êÊòØÂê¶ËØ≠Ê≥ïÊ≠£Á°Æ.\n",
    "- [MNLI](https://arxiv.org/abs/1704.05426) (Multi-Genre Natural Language Inference) ÁªôÂÆö‰∏Ä‰∏™ÂÅáËÆæÔºåÂà§Êñ≠Âè¶‰∏Ä‰∏™Âè•Â≠ê‰∏éËØ•ÂÅáËÆæÁöÑÂÖ≥Á≥ªÔºöentails, contradicts ÊàñËÄÖ unrelated„ÄÇ\n",
    "- [MRPC](https://www.microsoft.com/en-us/download/details.aspx?id=52398) (Microsoft Research Paraphrase Corpus) Âà§Êñ≠‰∏§‰∏™Âè•Â≠êÊòØÂê¶‰∫í‰∏∫paraphrases.\n",
    "- [QNLI](https://rajpurkar.github.io/SQuAD-explorer/) (Question-answering Natural Language Inference) Âà§Êñ≠Á¨¨2Âè•ÊòØÂê¶ÂåÖÂê´Á¨¨1Âè•ÈóÆÈ¢òÁöÑÁ≠îÊ°à„ÄÇ\n",
    "- [QQP](https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs) (Quora Question Pairs2) Âà§Êñ≠‰∏§‰∏™ÈóÆÂè•ÊòØÂê¶ËØ≠‰πâÁõ∏Âêå„ÄÇ\n",
    "- [RTE](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment) (Recognizing Textual Entailment)Âà§Êñ≠‰∏Ä‰∏™Âè•Â≠êÊòØÂê¶‰∏éÂÅáËÆæÊàêentailÂÖ≥Á≥ª„ÄÇ\n",
    "- [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank) Âà§Êñ≠‰∏Ä‰∏™Âè•Â≠êÁöÑÊÉÖÊÑüÊ≠£Ë¥üÂêë.\n",
    "- [STS-B](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) (Semantic Textual Similarity Benchmark) Âà§Êñ≠‰∏§‰∏™Âè•Â≠êÁöÑÁõ∏‰ººÊÄßÔºàÂàÜÊï∞‰∏∫1-5ÂàÜÔºâ„ÄÇ\n",
    "- [WNLI](https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html) (Winograd Natural Language Inference) Determine if a sentence with an anonymous pronoun and a sentence with this pronoun replaced are entailed or not. \n",
    "\n",
    "ÂØπ‰∫é‰ª•‰∏ä‰ªªÂä°ÔºåÊàë‰ª¨Â∞ÜÂ±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî®ÁÆÄÂçïÁöÑDatasetÂ∫ìÂä†ËΩΩÊï∞ÊçÆÈõÜÔºåÂêåÊó∂‰ΩøÁî®transformer‰∏≠ÁöÑ`Trainer`Êé•Âè£ÂØπÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "YZbiBDuGIrId"
   },
   "outputs": [],
   "source": [
    "GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RRkXuteIrIh"
   },
   "source": [
    "Êú¨notebookÁêÜËÆ∫‰∏äÂèØ‰ª•‰ΩøÁî®ÂêÑÁßçÂêÑÊ†∑ÁöÑtransformerÊ®°ÂûãÔºà[Ê®°ÂûãÈù¢Êùø](https://huggingface.co/models)ÔºâÔºåËß£ÂÜ≥‰ªª‰ΩïÊñáÊú¨ÂàÜÁ±ªÂàÜÁ±ª‰ªªÂä°„ÄÇ\n",
    "\n",
    "Â¶ÇÊûúÊÇ®ÊâÄÂ§ÑÁêÜÁöÑ‰ªªÂä°ÊúâÊâÄ‰∏çÂêåÔºåÂ§ßÊ¶ÇÁéáÂè™ÈúÄË¶ÅÂæàÂ∞èÁöÑÊîπÂä®‰æøÂèØ‰ª•‰ΩøÁî®Êú¨notebookËøõË°åÂ§ÑÁêÜ„ÄÇÂêåÊó∂ÔºåÊÇ®Â∫îËØ•Ê†πÊçÆÊÇ®ÁöÑGPUÊòæÂ≠òÊù•Ë∞ÉÊï¥ÂæÆË∞ÉËÆ≠ÁªÉÊâÄÈúÄË¶ÅÁöÑbtach sizeÂ§ßÂ∞èÔºåÈÅøÂÖçÊòæÂ≠òÊ∫¢Âá∫„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "zVvslsfMIrIh"
   },
   "outputs": [],
   "source": [
    "task = \"cola\"\n",
    "model_checkpoint = \"distilbert-base-uncased\" #Âä†ËΩΩËøô‰∏™Ê®°Âûã\n",
    "batch_size = 2 #ÊâπÊ¨°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Âä†ËΩΩÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "Êàë‰ª¨Â∞Ü‰ºö‰ΩøÁî®[ü§ó Datasets](https://github.com/huggingface/datasets)Â∫ìÊù•Âä†ËΩΩÊï∞ÊçÆÂíåÂØπÂ∫îÁöÑËØÑÊµãÊñπÂºè„ÄÇÊï∞ÊçÆÂä†ËΩΩÂíåËØÑÊµãÊñπÂºèÂä†ËΩΩÂè™ÈúÄË¶ÅÁÆÄÂçï‰ΩøÁî®`load_dataset`Âíå`load_metric`Âç≥ÂèØ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKx2zKs5IrIq"
   },
   "source": [
    "Èô§‰∫Ü`mnli-mm`‰ª•Â§ñÔºåÂÖ∂‰ªñ‰ªªÂä°ÈÉΩÂèØ‰ª•Áõ¥Êé•ÈÄöËøá‰ªªÂä°ÂêçÂ≠óËøõË°åÂä†ËΩΩ„ÄÇÊï∞ÊçÆÂä†ËΩΩ‰πãÂêé‰ºöËá™Âä®ÁºìÂ≠ò„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "s_AY1ATSIrIq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "actual_task = \"mnli\" if task == \"mnli-mm\" else task\n",
    "dataset = load_dataset(\"glue\", actual_task)\n",
    "metric = load_metric('glue', actual_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "Ëøô‰∏™`datasets`ÂØπË±°Êú¨Ë∫´ÊòØ‰∏ÄÁßç[`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict)Êï∞ÊçÆÁªìÊûÑ. ÂØπ‰∫éËÆ≠ÁªÉÈõÜ„ÄÅÈ™åËØÅÈõÜÂíåÊµãËØïÈõÜÔºåÂè™ÈúÄË¶Å‰ΩøÁî®ÂØπÂ∫îÁöÑkeyÔºàtrainÔºåvalidationÔºåtestÔºâÂç≥ÂèØÂæóÂà∞Áõ∏Â∫îÁöÑÊï∞ÊçÆ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWiVUF0jIrIv",
    "outputId": "b5d9d856-eaa3-4444-c650-1642a797cb77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3EtYfeHIrIz"
   },
   "source": [
    "ÁªôÂÆö‰∏Ä‰∏™Êï∞ÊçÆÂàáÂàÜÁöÑkeyÔºàtrain„ÄÅvalidationÊàñËÄÖtestÔºâÂíå‰∏ãÊ†áÂç≥ÂèØÊü•ÁúãÊï∞ÊçÆ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6HrpprwIrIz",
    "outputId": "1a1cf3a9-3349-40e6-88e2-912be6462daa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "‰∏∫‰∫ÜËÉΩÂ§üËøõ‰∏ÄÊ≠•ÁêÜËß£Êï∞ÊçÆÈïø‰ªÄ‰πàÊ†∑Â≠êÔºå‰∏ãÈù¢ÁöÑÂáΩÊï∞Â∞Ü‰ªéÊï∞ÊçÆÈõÜÈáåÈöèÊú∫ÈÄâÊã©Âá†‰∏™‰æãÂ≠êËøõË°åÂ±ïÁ§∫„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "SZy5tRB_IrI7",
    "outputId": "bf2a2b5b-0bda-41d0-edd4-db568b0cfcc8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I acknowledged that my father, he was tight as an owl.</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For him to do that would be a mistake.</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary sang a song, but Lee never did.</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>4506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John made Mary cooking Korean food.</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John sounded in the park.</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>3657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clouds cleared from the sky.</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>It is this hat that that he was wearing is certain.</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who are you gawking at?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Captain Oates died in order to save his comrades.</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>6912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The tree dropped fruit to the ground.</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnjDIuQ3IrI-"
   },
   "source": [
    "ËØÑ‰º∞meticÊòØ[`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric)ÁöÑ‰∏Ä‰∏™ÂÆû‰æã:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5o4rUteaIrI_",
    "outputId": "064cdacb-f8e3-432b-d504-715b59330275"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metric(name: \"glue\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
       "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
       "Args:\n",
       "    predictions: list of predictions to score.\n",
       "        Each translation should be tokenized into a list of tokens.\n",
       "    references: list of lists of references for each translation.\n",
       "        Each reference should be tokenized into a list of tokens.\n",
       "Returns: depending on the GLUE subset, one or several of:\n",
       "    \"accuracy\": Accuracy\n",
       "    \"f1\": F1 score\n",
       "    \"pearson\": Pearson Correlation\n",
       "    \"spearmanr\": Spearman Correlation\n",
       "    \"matthews_correlation\": Matthew Correlation\n",
       "Examples:\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0, 'f1': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
       "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
       "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'matthews_correlation': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAWdqcUBIrJC"
   },
   "source": [
    "Áõ¥Êé•Ë∞ÉÁî®metricÁöÑ`compute`ÊñπÊ≥ïÔºå‰º†ÂÖ•`labels`Âíå`predictions`Âç≥ÂèØÂæóÂà∞metricÁöÑÂÄºÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XN1Rq0aIrJC",
    "outputId": "0fa6d397-4d58-40ce-d14c-e527de32074d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matthews_correlation': 0.14462158210542375}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fake_preds = np.random.randint(0, 2, size=(64,))\n",
    "fake_labels = np.random.randint(0, 2, size=(64,))\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOCrQwPoIrJG"
   },
   "source": [
    "ÊØè‰∏Ä‰∏™ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°ÊâÄÂØπÂ∫îÁöÑmeticÊúâÊâÄ‰∏çÂêåÔºåÂÖ∑‰ΩìÂ¶Ç‰∏ã:\n",
    "\n",
    "- for CoLA: [Matthews Correlation Coefficient](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient)\n",
    "- for MNLI (matched or mismatched): Accuracy\n",
    "- for MRPC: Accuracy and [F1 score](https://en.wikipedia.org/wiki/F1_score)\n",
    "- for QNLI: Accuracy\n",
    "- for QQP: Accuracy and [F1 score](https://en.wikipedia.org/wiki/F1_score)\n",
    "- for RTE: Accuracy\n",
    "- for SST-2: Accuracy\n",
    "- for STS-B: [Pearson Correlation Coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) and [Spearman's_Rank_Correlation_Coefficient](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)\n",
    "- for WNLI: Accuracy\n",
    "\n",
    "ÊâÄ‰ª•‰∏ÄÂÆöË¶ÅÂ∞ÜmetricÂíå‰ªªÂä°ÂØπÈΩê"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Âú®Â∞ÜÊï∞ÊçÆÂñÇÂÖ•Ê®°Âûã‰πãÂâçÔºåÊàë‰ª¨ÈúÄË¶ÅÂØπÊï∞ÊçÆËøõË°åÈ¢ÑÂ§ÑÁêÜ„ÄÇÈ¢ÑÂ§ÑÁêÜÁöÑÂ∑•ÂÖ∑Âè´`Tokenizer`„ÄÇ`Tokenizer`È¶ñÂÖàÂØπËæìÂÖ•ËøõË°åtokenizeÔºåÁÑ∂ÂêéÂ∞ÜtokensËΩ¨Âåñ‰∏∫È¢ÑÊ®°Âûã‰∏≠ÈúÄË¶ÅÂØπÂ∫îÁöÑtoken IDÔºåÂÜçËΩ¨Âåñ‰∏∫Ê®°ÂûãÈúÄË¶ÅÁöÑËæìÂÖ•Ê†ºÂºè„ÄÇ\n",
    "\n",
    "‰∏∫‰∫ÜËææÂà∞Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁöÑÁõÆÁöÑÔºåÊàë‰ª¨‰ΩøÁî®`AutoTokenizer.from_pretrained`ÊñπÊ≥ïÂÆû‰æãÂåñÊàë‰ª¨ÁöÑtokenizerÔºåËøôÊ†∑ÂèØ‰ª•Á°Æ‰øùÔºö\n",
    "\n",
    "- Êàë‰ª¨ÂæóÂà∞‰∏Ä‰∏™‰∏éÈ¢ÑËÆ≠ÁªÉÊ®°Âûã‰∏Ä‰∏ÄÂØπÂ∫îÁöÑtokenizer„ÄÇ\n",
    "- ‰ΩøÁî®ÊåáÂÆöÁöÑÊ®°ÂûãcheckpointÂØπÂ∫îÁöÑtokenizerÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨‰πü‰∏ãËΩΩ‰∫ÜÊ®°ÂûãÈúÄË¶ÅÁöÑËØçË°®Â∫ìvocabularyÔºåÂáÜÁ°ÆÊù•ËØ¥ÊòØtokens vocabulary„ÄÇ\n",
    "\n",
    "Ëøô‰∏™Ë¢´‰∏ãËΩΩÁöÑtokens vocabulary‰ºöË¢´ÁºìÂ≠òËµ∑Êù•Ôºå‰ªéËÄåÂÜçÊ¨°‰ΩøÁî®ÁöÑÊó∂ÂÄô‰∏ç‰ºöÈáçÊñ∞‰∏ãËΩΩ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\Hmbb/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Hmbb/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\Hmbb/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Hmbb/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\Hmbb/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "Ê≥®ÊÑèÔºö`use_fast=True`Ë¶ÅÊ±ÇtokenizerÂøÖÈ°ªÊòØtransformers.PreTrainedTokenizerFastÁ±ªÂûãÔºåÂõ†‰∏∫Êàë‰ª¨Âú®È¢ÑÂ§ÑÁêÜÁöÑÊó∂ÂÄôÈúÄË¶ÅÁî®Âà∞fast tokenizerÁöÑ‰∏Ä‰∫õÁâπÊÆäÁâπÊÄßÔºàÊØîÂ¶ÇÂ§öÁ∫øÁ®ãÂø´ÈÄütokenizerÔºâ„ÄÇÂ¶ÇÊûúÂØπÂ∫îÁöÑÊ®°ÂûãÊ≤°Êúâfast tokenizerÔºåÂéªÊéâËøô‰∏™ÈÄâÈ°πÂç≥ÂèØ„ÄÇ\n",
    "\n",
    "Âá†‰πéÊâÄÊúâÊ®°ÂûãÂØπÂ∫îÁöÑtokenizerÈÉΩÊúâÂØπÂ∫îÁöÑfast tokenizer„ÄÇÊàë‰ª¨ÂèØ‰ª•Âú®[Ê®°ÂûãtokenizerÂØπÂ∫îË°®](https://huggingface.co/transformers/index.html#bigtable)ÈáåÊü•ÁúãÊâÄÊúâÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂØπÂ∫îÁöÑtokenizerÊâÄÊã•ÊúâÁöÑÁâπÁÇπ„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "tokenizerÊó¢ÂèØ‰ª•ÂØπÂçï‰∏™ÊñáÊú¨ËøõË°åÈ¢ÑÂ§ÑÁêÜÔºå‰πüÂèØ‰ª•ÂØπ‰∏ÄÂØπÊñáÊú¨ËøõË°åÈ¢ÑÂ§ÑÁêÜÔºåtokenizerÈ¢ÑÂ§ÑÁêÜÂêéÂæóÂà∞ÁöÑÊï∞ÊçÆÊª°Ë∂≥È¢ÑËÆ≠ÁªÉÊ®°ÂûãËæìÂÖ•Ê†ºÂºè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5hBlsrHIrJL",
    "outputId": "cf52c5d7-2273-453f-e78c-0f0e16fb8e0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 1010, 2023, 2028, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qo_0B1M2IrJM"
   },
   "source": [
    "ÂèñÂÜ≥‰∫éÊàë‰ª¨ÈÄâÊã©ÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºåÊàë‰ª¨Â∞Ü‰ºöÁúãÂà∞tokenizerÊúâ‰∏çÂêåÁöÑËøîÂõûÔºåtokenizerÂíåÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÊòØ‰∏Ä‰∏ÄÂØπÂ∫îÁöÑÔºåÊõ¥Â§ö‰ø°ÊÅØÂèØ‰ª•Âú®[ËøôÈáå](https://huggingface.co/transformers/preprocessing.html)ËøõË°åÂ≠¶‰π†„ÄÇ\n",
    "\n",
    "‰∏∫‰∫ÜÈ¢ÑÂ§ÑÁêÜÊàë‰ª¨ÁöÑÊï∞ÊçÆÔºåÊàë‰ª¨ÈúÄË¶ÅÁü•ÈÅì‰∏çÂêåÊï∞ÊçÆÂíåÂØπÂ∫îÁöÑÊï∞ÊçÆÊ†ºÂºèÔºåÂõ†Ê≠§Êàë‰ª¨ÂÆö‰πâ‰∏ãÈù¢Ëøô‰∏™dict„ÄÇ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "fyGdtK9oIrJM"
   },
   "outputs": [],
   "source": [
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbqtC4MrIrJO"
   },
   "source": [
    "ÂØπÊï∞ÊçÆÊ†ºÂºèËøõË°åÊ£ÄÊü•:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19GG646uIrJO",
    "outputId": "7091c67f-253d-486d-8407-90ac209cf49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Our friends won't buy this analysis, let alone the next one we propose.\n"
     ]
    }
   ],
   "source": [
    "sentence1_key, sentence2_key = task_to_keys[task]\n",
    "if sentence2_key is None:\n",
    "    print(f\"Sentence: {dataset['train'][0][sentence1_key]}\")\n",
    "else:\n",
    "    print(f\"Sentence 1: {dataset['train'][0][sentence1_key]}\")\n",
    "    print(f\"Sentence 2: {dataset['train'][0][sentence2_key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "ÈöèÂêéÂ∞ÜÈ¢ÑÂ§ÑÁêÜÁöÑ‰ª£Á†ÅÊîæÂà∞‰∏Ä‰∏™ÂáΩÊï∞‰∏≠Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples[sentence1_key], truncation=True)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "È¢ÑÂ§ÑÁêÜÂáΩÊï∞ÂèØ‰ª•Â§ÑÁêÜÂçï‰∏™Ê†∑Êú¨Ôºå‰πüÂèØ‰ª•ÂØπÂ§ö‰∏™Ê†∑Êú¨ËøõË°åÂ§ÑÁêÜ„ÄÇÂ¶ÇÊûúËæìÂÖ•ÊòØÂ§ö‰∏™Ê†∑Êú¨ÔºåÈÇ£‰πàËøîÂõûÁöÑÊòØ‰∏Ä‰∏™listÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-b70jh26IrJS",
    "outputId": "cea1c3e7-2633-445b-8aee-58ca8d9bcf66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102], [101, 2028, 2062, 18404, 2236, 3989, 1998, 1045, 1005, 1049, 3228, 2039, 1012, 102], [101, 2028, 2062, 18404, 2236, 3989, 2030, 1045, 1005, 1049, 3228, 2039, 1012, 102], [101, 1996, 2062, 2057, 2817, 16025, 1010, 1996, 13675, 16103, 2121, 2027, 2131, 1012, 102], [101, 2154, 2011, 2154, 1996, 8866, 2024, 2893, 14163, 8024, 3771, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(dataset['train'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "Êé•‰∏ãÊù•ÂØπÊï∞ÊçÆÈõÜdatasetsÈáåÈù¢ÁöÑÊâÄÊúâÊ†∑Êú¨ËøõË°åÈ¢ÑÂ§ÑÁêÜÔºåÂ§ÑÁêÜÁöÑÊñπÂºèÊòØ‰ΩøÁî®mapÂáΩÊï∞ÔºåÂ∞ÜÈ¢ÑÂ§ÑÁêÜÂáΩÊï∞prepare_train_featuresÂ∫îÁî®Âà∞Ôºàmap)ÊâÄÊúâÊ†∑Êú¨‰∏ä„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "DDtsaJeVIrJT"
   },
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "\n",
    "Êõ¥Â•ΩÁöÑÊòØÔºåËøîÂõûÁöÑÁªìÊûú‰ºöËá™Âä®Ë¢´ÁºìÂ≠òÔºåÈÅøÂÖç‰∏ãÊ¨°Â§ÑÁêÜÁöÑÊó∂ÂÄôÈáçÊñ∞ËÆ°ÁÆóÔºà‰ΩÜÊòØ‰πüË¶ÅÊ≥®ÊÑèÔºåÂ¶ÇÊûúËæìÂÖ•ÊúâÊîπÂä®ÔºåÂèØËÉΩ‰ºöË¢´ÁºìÂ≠òÂΩ±ÂìçÔºÅÔºâ„ÄÇdatasetsÂ∫ìÂáΩÊï∞‰ºöÂØπËæìÂÖ•ÁöÑÂèÇÊï∞ËøõË°åÊ£ÄÊµãÔºåÂà§Êñ≠ÊòØÂê¶ÊúâÂèòÂåñÔºåÂ¶ÇÊûúÊ≤°ÊúâÂèòÂåñÂ∞±‰ΩøÁî®ÁºìÂ≠òÊï∞ÊçÆÔºåÂ¶ÇÊûúÊúâÂèòÂåñÂ∞±ÈáçÊñ∞Â§ÑÁêÜ„ÄÇ‰ΩÜÂ¶ÇÊûúËæìÂÖ•ÂèÇÊï∞‰∏çÂèòÔºåÊÉ≥ÊîπÂèòËæìÂÖ•ÁöÑÊó∂ÂÄôÔºåÊúÄÂ•ΩÊ∏ÖÁêÜË∞ÉËøô‰∏™ÁºìÂ≠ò„ÄÇÊ∏ÖÁêÜÁöÑÊñπÂºèÊòØ‰ΩøÁî®`load_from_cache_file=False`ÂèÇÊï∞„ÄÇÂè¶Â§ñÔºå‰∏äÈù¢‰ΩøÁî®Âà∞ÁöÑ`batched=True`Ëøô‰∏™ÂèÇÊï∞ÊòØtokenizerÁöÑÁâπÁÇπÔºå‰ª•‰∏∫Ëøô‰ºö‰ΩøÁî®Â§öÁ∫øÁ®ãÂêåÊó∂Âπ∂Ë°åÂØπËæìÂÖ•ËøõË°åÂ§ÑÁêÜ„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°Âûã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Êó¢ÁÑ∂Êï∞ÊçÆÂ∑≤ÁªèÂáÜÂ§áÂ•Ω‰∫ÜÔºåÁé∞Âú®Êàë‰ª¨ÈúÄË¶Å‰∏ãËΩΩÂπ∂Âä†ËΩΩÊàë‰ª¨ÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºåÁÑ∂ÂêéÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°Âûã„ÄÇÊó¢ÁÑ∂Êàë‰ª¨ÊòØÂÅöseq2seq‰ªªÂä°ÔºåÈÇ£‰πàÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∏™ËÉΩËß£ÂÜ≥Ëøô‰∏™‰ªªÂä°ÁöÑÊ®°ÂûãÁ±ª„ÄÇÊàë‰ª¨‰ΩøÁî®`AutoModelForSequenceClassification` Ëøô‰∏™Á±ª„ÄÇÂíåtokenizerÁõ∏‰ººÔºå`from_pretrained`ÊñπÊ≥ïÂêåÊ†∑ÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨‰∏ãËΩΩÂπ∂Âä†ËΩΩÊ®°ÂûãÔºåÂêåÊó∂‰πü‰ºöÂØπÊ®°ÂûãËøõË°åÁºìÂ≠òÔºåÂ∞±‰∏ç‰ºöÈáçÂ§ç‰∏ãËΩΩÊ®°ÂûãÂï¶„ÄÇ\n",
    "\n",
    "ÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºöSTS-BÊòØ‰∏Ä‰∏™ÂõûÂΩíÈóÆÈ¢òÔºåMNLIÊòØ‰∏Ä‰∏™3ÂàÜÁ±ªÈóÆÈ¢òÔºö\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154,
     "referenced_widgets": [
      "fc7dcd466978430fa564001d1fa8959d",
      "477b25083c3541efb4339e0ceef4e522",
      "8ead287f55c1422fab004d24cbc23d62",
      "ac5fb6c061aa432b82f1b8a499ece40a",
      "cae8ea12d2c943d4ad2f1c4812237916",
      "b778869a30d64bd5aa628163a83b8c45",
      "9b7051f36fe1427ab13a8effbe89d2e3",
      "bd75bd9e0afe4759aa2f747f8562a55c",
      "d7f5cbfcaa3e41f783b24dee39d49e6a",
      "d90bc3f2b14746d18636fe3dbe490c04",
      "79b6d1ffa7b6423fab3ca70b116a75c2"
     ]
    },
    "id": "TlqNaB8jIrJW",
    "outputId": "4d048460-7bb0-44a7-dca6-75ce19bebe5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Hmbb/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\Hmbb/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = 3 if task.startswith(\"mnli\") else 1 if task==\"stsb\" else 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "Áî±‰∫éÊàë‰ª¨ÂæÆË∞ÉÁöÑ‰ªªÂä°ÊòØÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°ÔºåËÄåÊàë‰ª¨Âä†ËΩΩÁöÑÊòØÈ¢ÑËÆ≠ÁªÉÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÊâÄ‰ª•‰ºöÊèêÁ§∫Êàë‰ª¨Âä†ËΩΩÊ®°ÂûãÁöÑÊó∂ÂÄôÊâîÊéâ‰∫Ü‰∏Ä‰∫õ‰∏çÂåπÈÖçÁöÑÁ•ûÁªèÁΩëÁªúÂèÇÊï∞ÔºàÊØîÂ¶ÇÔºöÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÁöÑÁ•ûÁªèÁΩëÁªúheadË¢´ÊâîÊéâ‰∫ÜÔºåÂêåÊó∂ÈöèÊú∫ÂàùÂßãÂåñ‰∫ÜÊñáÊú¨ÂàÜÁ±ªÁöÑÁ•ûÁªèÁΩëÁªúheadÔºâ„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "‰∏∫‰∫ÜËÉΩÂ§üÂæóÂà∞‰∏Ä‰∏™`Trainer`ËÆ≠ÁªÉÂ∑•ÂÖ∑ÔºåÊàë‰ª¨ËøòÈúÄË¶Å3‰∏™Ë¶ÅÁ¥†ÔºåÂÖ∂‰∏≠ÊúÄÈáçË¶ÅÁöÑÊòØËÆ≠ÁªÉÁöÑËÆæÂÆö/ÂèÇÊï∞ [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments)„ÄÇËøô‰∏™ËÆ≠ÁªÉËÆæÂÆöÂåÖÂê´‰∫ÜËÉΩÂ§üÂÆö‰πâËÆ≠ÁªÉËøáÁ®ãÁöÑÊâÄÊúâÂ±ûÊÄß„ÄÇ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Bliy8zgjIrJY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "metric_name = \"pearson\" if task == \"stsb\" else \"matthews_correlation\" if task == \"cola\" else \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"test-glue\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "‰∏äÈù¢evaluation_strategy = \"epoch\"ÂèÇÊï∞ÂëäËØâËÆ≠ÁªÉ‰ª£Á†ÅÔºöÊàë‰ª¨ÊØè‰∏™epcoh‰ºöÂÅö‰∏ÄÊ¨°È™åËØÅËØÑ‰º∞„ÄÇ\n",
    "\n",
    "‰∏äÈù¢batch_sizeÂú®Ëøô‰∏™notebook‰πãÂâçÂÆö‰πâÂ•Ω‰∫Ü„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sZOdRlRIrJd"
   },
   "source": [
    "ÊúÄÂêéÔºåÁî±‰∫é‰∏çÂêåÁöÑ‰ªªÂä°ÈúÄË¶Å‰∏çÂêåÁöÑËØÑÊµãÊåáÊ†áÔºåÊàë‰ª¨ÂÆö‰∏Ä‰∏™ÂáΩÊï∞Êù•Ê†πÊçÆ‰ªªÂä°ÂêçÂ≠óÂæóÂà∞ËØÑ‰ª∑ÊñπÊ≥ï:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "UmvbnJ9JIrJd"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if task != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "ÂÖ®ÈÉ®‰º†Áªô `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 90.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m validation_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_mismatched\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnli-mm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_matched\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnli\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalidation_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\transformers\\trainer.py:437\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device:\n\u001b[1;32m--> 437\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\transformers\\trainer.py:703\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[1;34m(self, model, device)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[1;32m--> 703\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1154\u001b[0m             device,\n\u001b[0;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1156\u001b[0m             non_blocking,\n\u001b[0;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1158\u001b[0m         )\n\u001b[1;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "validation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\" if task == \"mnli\" else \"validation\"\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "ÂºÄÂßãËÆ≠ÁªÉ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uNx5pyRlIrJh",
    "outputId": "bc13d4b6-b797-4522-bd3b-887b4a01e3e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10690\n",
      "  Number of trainable parameters = 66955010\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 90.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\transformers\\trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1498\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\transformers\\trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1747\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1749\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1752\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1755\u001b[0m ):\n\u001b[0;32m   1756\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\transformers\\trainer.py:2526\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2524\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m   2525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2526\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_analysis\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKASz-2vIrJi"
   },
   "source": [
    "ËÆ≠ÁªÉÂÆåÊàêÂêéËøõË°åËØÑ‰º∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "UOUcBkX8IrJi",
    "outputId": "29f903c0-9124-4a20-b2e4-159d39a265a2"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffP-VQOyIrJk"
   },
   "source": [
    "To see how your model fared you can compare it to the [GLUE Benchmark leaderboard](https://gluebenchmark.com/leaderboard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7k8ge1L1IrJk"
   },
   "source": [
    "## Ë∂ÖÂèÇÊï∞ÊêúÁ¥¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNfajuw_IrJl"
   },
   "source": [
    "`Trainer`ÂêåÊ†∑ÊîØÊåÅË∂ÖÂèÇÊêúÁ¥¢Ôºå‰ΩøÁî®[optuna](https://optuna.org/) or [Ray Tune](https://docs.ray.io/en/latest/tune/)‰ª£Á†ÅÂ∫ì„ÄÇ\n",
    "\n",
    "ÂèçÊ≥®Èáä‰∏ãÈù¢‰∏§Ë°åÂÆâË£Ö‰æùËµñÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUdakNBhIrJl"
   },
   "outputs": [],
   "source": [
    "! pip install optuna\n",
    "! pip install ray[tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttfT0CqaIrJm"
   },
   "source": [
    "Ë∂ÖÂèÇÊêúÁ¥¢Êó∂Ôºå`Trainer`Â∞Ü‰ºöËøîÂõûÂ§ö‰∏™ËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãÔºåÊâÄ‰ª•ÈúÄË¶Å‰º†ÂÖ•‰∏Ä‰∏™ÂÆö‰πâÂ•ΩÁöÑÊ®°Âûã‰ªéËÄåËÆ©`Trainer`ÂèØ‰ª•‰∏çÊñ≠ÈáçÊñ∞ÂàùÂßãÂåñËØ•‰º†ÂÖ•ÁöÑÊ®°ÂûãÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "8sgjdLKcIrJm"
   },
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMXfVJO4IrJo"
   },
   "source": [
    "Âíå‰πãÂâçË∞ÉÁî® `Trainer`Á±ª‰ºº:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71pt6N0eIrJo",
    "outputId": "8e1a7982-0e3a-491f-bac4-f53114d6a384"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.9.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQxrzFP4IrJq"
   },
   "source": [
    "Ë∞ÉÁî®ÊñπÊ≥ï`hyperparameter_search`„ÄÇÊ≥®ÊÑèÔºåËøô‰∏™ËøáÁ®ãÂèØËÉΩÂæà‰πÖÔºåÊàë‰ª¨ÂèØ‰ª•ÂÖàÁî®ÈÉ®ÂàÜÊï∞ÊçÆÈõÜËøõË°åË∂ÖÂèÇÊêúÁ¥¢ÔºåÂÜçËøõË°åÂÖ®ÈáèËÆ≠ÁªÉ„ÄÇ\n",
    "ÊØîÂ¶Ç‰ΩøÁî®1/10ÁöÑÊï∞ÊçÆËøõË°åÊêúÁ¥¢Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NboJ7kDOIrJq"
   },
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUTD72qCIrJs"
   },
   "source": [
    "`hyperparameter_search`‰ºöËøîÂõûÊïàÊûúÊúÄÂ•ΩÁöÑÊ®°ÂûãÁõ∏ÂÖ≥ÁöÑÂèÇÊï∞\bÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Psi4JymeIrJs"
   },
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFdjWbRIIrJu"
   },
   "source": [
    "Â∞Ü`Trainner`ËÆæÁΩÆ‰∏∫ÊêúÁ¥¢Âà∞ÁöÑÊúÄÂ•ΩÂèÇÊï∞ÔºåËøõË°åËÆ≠ÁªÉÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsJ6sqdGIrJu"
   },
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m09tZgZRIrJv"
   },
   "source": [
    "ÊúÄÂêéÂà´Âøò‰∫ÜÔºåÊü•ÁúãÂ¶Ç‰Ωï‰∏ä‰º†Ê®°Âûã Ôºå‰∏ä‰º†Ê®°ÂûãÂà∞](https://huggingface.co/transformers/model_sharing.html) Âà∞[ü§ó Model Hub](https://huggingface.co/models)„ÄÇÈöèÂêéÊÇ®Â∞±ÂèØ‰ª•ÂÉèËøô‰∏™notebook‰∏ÄÂºÄÂßã‰∏ÄÊ†∑ÔºåÁõ¥Êé•Áî®Ê®°ÂûãÂêçÂ≠óÂ∞±ËÉΩ‰ΩøÁî®ÊÇ®Ëá™Â∑±‰∏ä‰º†ÁöÑÊ®°ÂûãÂï¶„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjO3bqHz4d1d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "4.1-ÊñáÊú¨ÂàÜÁ±ª",
   "provenance": []
  },
  "interpreter": {
   "hash": "3bfce0b4c492a35815b5705a19fe374a7eea0baaa08b34d90450caf1fe9ce20b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "477b25083c3541efb4339e0ceef4e522": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79b6d1ffa7b6423fab3ca70b116a75c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ead287f55c1422fab004d24cbc23d62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b7051f36fe1427ab13a8effbe89d2e3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b778869a30d64bd5aa628163a83b8c45",
      "value": "Downloading: 100%"
     }
    },
    "9b7051f36fe1427ab13a8effbe89d2e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac5fb6c061aa432b82f1b8a499ece40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7f5cbfcaa3e41f783b24dee39d49e6a",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd75bd9e0afe4759aa2f747f8562a55c",
      "value": 267967963
     }
    },
    "b778869a30d64bd5aa628163a83b8c45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd75bd9e0afe4759aa2f747f8562a55c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cae8ea12d2c943d4ad2f1c4812237916": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79b6d1ffa7b6423fab3ca70b116a75c2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d90bc3f2b14746d18636fe3dbe490c04",
      "value": " 268M/268M [00:05&lt;00:00, 46.7MB/s]"
     }
    },
    "d7f5cbfcaa3e41f783b24dee39d49e6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d90bc3f2b14746d18636fe3dbe490c04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc7dcd466978430fa564001d1fa8959d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ead287f55c1422fab004d24cbc23d62",
       "IPY_MODEL_ac5fb6c061aa432b82f1b8a499ece40a",
       "IPY_MODEL_cae8ea12d2c943d4ad2f1c4812237916"
      ],
      "layout": "IPY_MODEL_477b25083c3541efb4339e0ceef4e522"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
